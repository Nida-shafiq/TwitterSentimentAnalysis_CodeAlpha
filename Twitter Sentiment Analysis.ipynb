{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b6c4f4-a37c-4674-bb4d-0f6668b3919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in f:\\anaconda\\envs\\ann\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66ebd44-f0d2-48ac-8845-f3143590abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in f:\\anaconda\\envs\\ann\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in f:\\anaconda\\envs\\ann\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5511d2fc-3ea4-4836-a587-544cd254765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4484becc-1ef7-4fbe-a9ed-da34c0533b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef75bb2-ff4d-4593-ad70-cb1dc189d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in f:\\anaconda\\envs\\ann\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667e19f9-c9f3-4a20-9557-8b1b21a75993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "client = tweepy.Client(bearer_token=\"YOUR_TOKEN\", wait_on_rate_limit=True)\n",
    "\n",
    "# For older tweepy versions with `API`\n",
    "auth = tweepy.OAuthHandler(\"API_KEY\", \"API_SECRET\")\n",
    "auth.set_access_token(\"ACCESS_TOKEN\", \"ACCESS_SECRET\")\n",
    "\n",
    "api = tweepy.API(auth, timeout=60)  # Set higher timeout (default is usually 5s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f31a22b-dccf-41b0-bf2e-0e03c1be3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "\n",
    "bearer_token = os.getenv(\"TWITTER_BEARER_TOKEN\")\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bafab2e-c23c-4300-889c-99e04b707d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 60.00%\n",
      "Negative tweets percentage: 30.00%\n",
      "Neutral tweets percentage: 10.00%\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "- I love this movie! It was fantastic!\n",
      "- Meh, it was okay. Nothing special.\n",
      "- Absolutely loved the performance.\n",
      "- Amazing quality and great value!\n",
      "- It's just fine. Not bad, not great.\n",
      "- This makes me so happy!\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "- This is the worst product I have ever used.\n",
      "- Terrible experience. I want my money back!\n",
      "- Disappointed by the service.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "class TwitterClientOffline:\n",
    "    '''\n",
    "    Fake Twitter client for local sentiment testing\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # No API keys needed\n",
    "        pass\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(r\"(@\\w+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self):\n",
    "        '''\n",
    "        Fake tweets for testing sentiment analysis\n",
    "        '''\n",
    "        sample_tweets = [\n",
    "            \"I love this movie! It was fantastic!\",\n",
    "            \"This is the worst product I have ever used.\",\n",
    "            \"Meh, it was okay. Nothing special.\",\n",
    "            \"Absolutely loved the performance.\",\n",
    "            \"Terrible experience. I want my money back!\",\n",
    "            \"Neutral feelings about this event.\",\n",
    "            \"Amazing quality and great value!\",\n",
    "            \"Disappointed by the service.\",\n",
    "            \"It's just fine. Not bad, not great.\",\n",
    "            \"This makes me so happy!\"\n",
    "        ]\n",
    "        \n",
    "        return [{'text': tweet, 'sentiment': self.get_tweet_sentiment(tweet)} for tweet in sample_tweets]\n",
    "\n",
    "def main():\n",
    "    api = TwitterClientOffline()\n",
    "    tweets = api.get_tweets()\n",
    "\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    neutral = len(tweets) - len(ptweets) - len(ntweets)\n",
    "\n",
    "    print(f\"Positive tweets percentage: {100 * len(ptweets) / len(tweets):.2f}%\")\n",
    "    print(f\"Negative tweets percentage: {100 * len(ntweets) / len(tweets):.2f}%\")\n",
    "    print(f\"Neutral tweets percentage: {100 * neutral / len(tweets):.2f}%\")\n",
    "\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets:\n",
    "        print(\"-\", tweet['text'])\n",
    "\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets:\n",
    "        print(\"-\", tweet['text'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cc4988-def0-444b-83ca-45a907a12164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Set your Twitter API credentials here\n",
    "consumer_key = 'YOUR_CONSUMER_KEY'\n",
    "consumer_secret = 'YOUR_CONSUMER_SECRET'\n",
    "access_token = 'YOUR_ACCESS_TOKEN'\n",
    "access_token_secret = 'YOUR_ACCESS_TOKEN_SECRET'\n",
    "\n",
    "url = \"https://api.twitter.com/2/tweets/search/recent\"  # Use Twitter's recent search endpoint\n",
    "params = {\n",
    "    'query': 'OpenAI',\n",
    "    'max_results': '10'\n",
    "}\n",
    "\n",
    "# Use the proper authentication\n",
    "auth = HTTPBasicAuth(consumer_key, consumer_secret)\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, params=params, auth=auth)\n",
    "    response.raise_for_status()  # Will raise an error for HTTP error responses\n",
    "    print(\"Response:\", response.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed3c278-0ed4-480d-a0ac-943d194effe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data columns: Index(['ID', 'Source', 'Label', 'Text'], dtype='object')\n",
      "Validation data columns: Index(['ID', 'Source', 'Label', 'Text'], dtype='object')\n",
      "Training Data Sentiment Analysis:\n",
      "Positive tweets percentage: 45.81%\n",
      "Negative tweets percentage: 28.31%\n",
      "Neutral tweets percentage: 25.88%\n",
      "\n",
      "Validation Data Sentiment Analysis:\n",
      "Positive tweets percentage: 47.90%\n",
      "Negative tweets percentage: 32.30%\n",
      "Neutral tweets percentage: 19.80%\n",
      "\n",
      "Sample Positive tweets:\n",
      "So I spent a few hours making something for fun. . . If you don't know I am a HUGE @Borderlands fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
      "So I spent a couple of hours doing something for fun... If you don't know that I'm a huge @ Borderlands fan and Maya is one of my favorite characters, I decided to make a wallpaper for my PC.. Here's the original picture compared to the creation I made:) Have fun! pic.twitter.com / mLsI5wf9Jg\n",
      "So I spent a few hours doing something for fun... If you don't know I'm a HUGE @ Borderlands fan and Maya is one of my favorite characters.\n",
      "So I spent a few hours making something for fun. . . If you don't know I am a HUGE RhandlerR fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
      "2010 So I spent a few hours making something for fun. . . If you don't know I am a HUGE RhandlerR fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
      "\n",
      "Sample Negative tweets:\n",
      "the biggest dissappoinment in my life came out a year ago fuck borderlands 3\n",
      "The biggest disappointment of my life came a year ago.\n",
      "The biggest disappointment of my life came a year ago.\n",
      "the biggest dissappoinment in my life coming out a year ago fuck borderlands 3\n",
      "For the biggest male dissappoinment in my life came hanging out a year time ago fuck borderlands 3\n",
      "\n",
      "Sample Positive tweets:\n",
      "Now the President is slapping Americans in the face that he really did commit an unlawful act after his  acquittal! From Discover on Google vanityfair.com/news/2020/02/tâ€¦\n",
      "Thank you @EAMaddenNFL!! \n",
      "\n",
      "New TE Austin Hooper in the ORANGE & BROWN!! \n",
      "\n",
      "#Browns | @AustinHooper18 \n",
      "\n",
      " pic.twitter.com/GRg4xzFKOn\n",
      "Rocket League, Sea of Thieves or Rainbow Six: SiegeðŸ¤”? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow\n",
      "my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao\n",
      "The professional dota 2 scene is fucking exploding and I completely welcome it.\n",
      "\n",
      "Get the garbage out.\n",
      "\n",
      "Sample Negative tweets:\n",
      "I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tomâ€™s great auntie as â€˜Hayley canâ€™t get out of bedâ€™ and told to his grandma, who now thinks Iâ€™m a lazy, terrible person ðŸ¤£\n",
      "@Microsoft Why do I pay for WORD when it functions so poorly on my @SamsungUS Chromebook? ðŸ™„\n",
      "CSGO matchmaking is so full of closet hacking, it's a truly awful game.\n",
      "Hi @EAHelp Iâ€™ve had Madeleine McCann in my cellar for the past 13 years and the little sneaky thing just escaped whilst I was loading up some fifa points, she took my card and Iâ€™m having to use my paypal account but it isnâ€™t working, can you help me resolve it please?\n",
      "FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        \"\"\"\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements. It ensures only valid strings are processed.\n",
    "        \"\"\"\n",
    "        if not isinstance(tweet, str):\n",
    "            return \"\"  # Return empty string for non-string values (e.g., NaN, float)\n",
    "        \n",
    "        return ' '.join(re.sub(r\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        \"\"\"\n",
    "        Utility function to classify sentiment of passed tweet using TextBlob's sentiment method.\n",
    "        \"\"\"\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def analyze_sentiment(self, df, tweet_column):\n",
    "        \"\"\"\n",
    "        Function to apply sentiment analysis to a dataset of tweets.\n",
    "        \"\"\"\n",
    "        df['sentiment'] = df[tweet_column].apply(self.get_tweet_sentiment)\n",
    "        return df\n",
    "\n",
    "    def calculate_sentiment_percentage(self, df):\n",
    "        \"\"\"\n",
    "        Function to calculate the percentage of each sentiment category.\n",
    "        \"\"\"\n",
    "        total_tweets = len(df)\n",
    "        positive_tweets = len(df[df['sentiment'] == 'positive'])\n",
    "        negative_tweets = len(df[df['sentiment'] == 'negative'])\n",
    "        neutral_tweets = len(df[df['sentiment'] == 'neutral'])\n",
    "\n",
    "        print(f\"Positive tweets percentage: {100 * positive_tweets / total_tweets:.2f}%\")\n",
    "        print(f\"Negative tweets percentage: {100 * negative_tweets / total_tweets:.2f}%\")\n",
    "        print(f\"Neutral tweets percentage: {100 * neutral_tweets / total_tweets:.2f}%\")\n",
    "\n",
    "    def display_sample_tweets(self, df):\n",
    "        \"\"\"\n",
    "        Function to display sample tweets based on sentiment.\n",
    "        \"\"\"\n",
    "        ptweets = df[df['sentiment'] == 'positive']\n",
    "        ntweets = df[df['sentiment'] == 'negative']\n",
    "\n",
    "        print(\"\\nSample Positive tweets:\")\n",
    "        for tweet in ptweets.head(5)['Text']:\n",
    "            print(tweet)\n",
    "\n",
    "        print(\"\\nSample Negative tweets:\")\n",
    "        for tweet in ntweets.head(5)['Text']:\n",
    "            print(tweet)\n",
    "\n",
    "\n",
    "def load_and_process_data(training_path, validation_path):\n",
    "    \"\"\"\n",
    "    Load datasets, process the tweets, and apply sentiment analysis.\n",
    "    \"\"\"\n",
    "    # Load training and validation datasets\n",
    "    df_train = pd.read_csv(training_path, header=None)\n",
    "    df_valid = pd.read_csv(validation_path, header=None)\n",
    "\n",
    "    # Manually rename columns\n",
    "    df_train.columns = ['ID', 'Source', 'Label', 'Text']\n",
    "    df_valid.columns = ['ID', 'Source', 'Label', 'Text']\n",
    "\n",
    "    # Print columns to confirm renaming\n",
    "    print(f\"Training data columns: {df_train.columns}\")\n",
    "    print(f\"Validation data columns: {df_valid.columns}\")\n",
    "\n",
    "    # Use 'Text' column for sentiment analysis\n",
    "    tweet_column = 'Text'\n",
    "\n",
    "    # Initialize sentiment analyzer\n",
    "    analyzer = SentimentAnalyzer()\n",
    "\n",
    "    # Analyze sentiment for both training and validation datasets\n",
    "    df_train = analyzer.analyze_sentiment(df_train, tweet_column)\n",
    "    df_valid = analyzer.analyze_sentiment(df_valid, tweet_column)\n",
    "\n",
    "    # Calculate sentiment percentage\n",
    "    print(\"Training Data Sentiment Analysis:\")\n",
    "    analyzer.calculate_sentiment_percentage(df_train)\n",
    "\n",
    "    print(\"\\nValidation Data Sentiment Analysis:\")\n",
    "    analyzer.calculate_sentiment_percentage(df_valid)\n",
    "\n",
    "    # Display sample tweets\n",
    "    analyzer.display_sample_tweets(df_train)\n",
    "    analyzer.display_sample_tweets(df_valid)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the correct file paths for your datasets\n",
    "    training_path = 'twitter_training.csv'  # Replace with your training dataset path\n",
    "    validation_path = 'twitter_validation.csv'  # Replace with your validation dataset path\n",
    "\n",
    "    # Load and process data\n",
    "    load_and_process_data(training_path, validation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65b27f-0c73-4105-b929-3863863d545d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
