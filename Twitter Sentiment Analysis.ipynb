{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b6c4f4-a37c-4674-bb4d-0f6668b3919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in f:\\anaconda\\envs\\ann\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66ebd44-f0d2-48ac-8845-f3143590abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in f:\\anaconda\\envs\\ann\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in f:\\anaconda\\envs\\ann\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in f:\\anaconda\\envs\\ann\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5511d2fc-3ea4-4836-a587-544cd254765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Nida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4484becc-1ef7-4fbe-a9ed-da34c0533b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef75bb2-ff4d-4593-ad70-cb1dc189d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in f:\\anaconda\\envs\\ann\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from tweepy) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\ann\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667e19f9-c9f3-4a20-9557-8b1b21a75993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "client = tweepy.Client(bearer_token=\"YOUR_TOKEN\", wait_on_rate_limit=True)\n",
    "\n",
    "# For older tweepy versions with `API`\n",
    "auth = tweepy.OAuthHandler(\"API_KEY\", \"API_SECRET\")\n",
    "auth.set_access_token(\"ACCESS_TOKEN\", \"ACCESS_SECRET\")\n",
    "\n",
    "api = tweepy.API(auth, timeout=60)  # Set higher timeout (default is usually 5s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f31a22b-dccf-41b0-bf2e-0e03c1be3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "\n",
    "bearer_token = os.getenv(\"TWITTER_BEARER_TOKEN\")\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bafab2e-c23c-4300-889c-99e04b707d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 60.00%\n",
      "Negative tweets percentage: 30.00%\n",
      "Neutral tweets percentage: 10.00%\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "- I love this movie! It was fantastic!\n",
      "- Meh, it was okay. Nothing special.\n",
      "- Absolutely loved the performance.\n",
      "- Amazing quality and great value!\n",
      "- It's just fine. Not bad, not great.\n",
      "- This makes me so happy!\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "- This is the worst product I have ever used.\n",
      "- Terrible experience. I want my money back!\n",
      "- Disappointed by the service.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "class TwitterClientOffline:\n",
    "    '''\n",
    "    Fake Twitter client for local sentiment testing\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # No API keys needed\n",
    "        pass\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(r\"(@\\w+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self):\n",
    "        '''\n",
    "        Fake tweets for testing sentiment analysis\n",
    "        '''\n",
    "        sample_tweets = [\n",
    "            \"I love this movie! It was fantastic!\",\n",
    "            \"This is the worst product I have ever used.\",\n",
    "            \"Meh, it was okay. Nothing special.\",\n",
    "            \"Absolutely loved the performance.\",\n",
    "            \"Terrible experience. I want my money back!\",\n",
    "            \"Neutral feelings about this event.\",\n",
    "            \"Amazing quality and great value!\",\n",
    "            \"Disappointed by the service.\",\n",
    "            \"It's just fine. Not bad, not great.\",\n",
    "            \"This makes me so happy!\"\n",
    "        ]\n",
    "        \n",
    "        return [{'text': tweet, 'sentiment': self.get_tweet_sentiment(tweet)} for tweet in sample_tweets]\n",
    "\n",
    "def main():\n",
    "    api = TwitterClientOffline()\n",
    "    tweets = api.get_tweets()\n",
    "\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    neutral = len(tweets) - len(ptweets) - len(ntweets)\n",
    "\n",
    "    print(f\"Positive tweets percentage: {100 * len(ptweets) / len(tweets):.2f}%\")\n",
    "    print(f\"Negative tweets percentage: {100 * len(ntweets) / len(tweets):.2f}%\")\n",
    "    print(f\"Neutral tweets percentage: {100 * neutral / len(tweets):.2f}%\")\n",
    "\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets:\n",
    "        print(\"-\", tweet['text'])\n",
    "\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets:\n",
    "        print(\"-\", tweet['text'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cc4988-def0-444b-83ca-45a907a12164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Set your Twitter API credentials here\n",
    "consumer_key = 'YOUR_CONSUMER_KEY'\n",
    "consumer_secret = 'YOUR_CONSUMER_SECRET'\n",
    "access_token = 'YOUR_ACCESS_TOKEN'\n",
    "access_token_secret = 'YOUR_ACCESS_TOKEN_SECRET'\n",
    "\n",
    "url = \"https://api.twitter.com/2/tweets/search/recent\"  # Use Twitter's recent search endpoint\n",
    "params = {\n",
    "    'query': 'OpenAI',\n",
    "    'max_results': '10'\n",
    "}\n",
    "\n",
    "# Use the proper authentication\n",
    "auth = HTTPBasicAuth(consumer_key, consumer_secret)\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, params=params, auth=auth)\n",
    "    response.raise_for_status()  # Will raise an error for HTTP error responses\n",
    "    print(\"Response:\", response.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed3c278-0ed4-480d-a0ac-943d194effe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data columns: Index(['ID', 'Source', 'Label', 'Text'], dtype='object')\n",
      "Validation data columns: Index(['ID', 'Source', 'Label', 'Text'], dtype='object')\n",
      "Training Data Sentiment Analysis:\n",
      "Positive tweets percentage: 45.81%\n",
      "Negative tweets percentage: 28.31%\n",
      "Neutral tweets percentage: 25.88%\n",
      "\n",
      "Validation Data Sentiment Analysis:\n",
      "Positive tweets percentage: 47.90%\n",
      "Negative tweets percentage: 32.30%\n",
      "Neutral tweets percentage: 19.80%\n",
      "\n",
      "Sample Positive tweets:\n",
      "So I spent a few hours making something for fun. . . If you don't know I am a HUGE @Borderlands fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
      "So I spent a couple of hours doing something for fun... If you don't know that I'm a huge @ Borderlands fan and Maya is one of my favorite characters, I decided to make a wallpaper for my PC.. Here's the original picture compared to the creation I made:) Have fun! pic.twitter.com / mLsI5wf9Jg\n",
      "So I spent a few hours doing something for fun... If you don't know I'm a HUGE @ Borderlands fan and Maya is one of my favorite characters.\n",
      "So I spent a few hours making something for fun. . . If you don't know I am a HUGE RhandlerR fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
      "2010 So I spent a few hours making something for fun. . . If you don't know I am a HUGE RhandlerR fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
      "\n",
      "Sample Negative tweets:\n",
      "the biggest dissappoinment in my life came out a year ago fuck borderlands 3\n",
      "The biggest disappointment of my life came a year ago.\n",
      "The biggest disappointment of my life came a year ago.\n",
      "the biggest dissappoinment in my life coming out a year ago fuck borderlands 3\n",
      "For the biggest male dissappoinment in my life came hanging out a year time ago fuck borderlands 3\n",
      "\n",
      "Sample Positive tweets:\n",
      "Now the President is slapping Americans in the face that he really did commit an unlawful act after his  acquittal! From Discover on Google vanityfair.com/news/2020/02/t…\n",
      "Thank you @EAMaddenNFL!! \n",
      "\n",
      "New TE Austin Hooper in the ORANGE & BROWN!! \n",
      "\n",
      "#Browns | @AustinHooper18 \n",
      "\n",
      " pic.twitter.com/GRg4xzFKOn\n",
      "Rocket League, Sea of Thieves or Rainbow Six: Siege🤔? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow\n",
      "my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao\n",
      "The professional dota 2 scene is fucking exploding and I completely welcome it.\n",
      "\n",
      "Get the garbage out.\n",
      "\n",
      "Sample Negative tweets:\n",
      "I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom’s great auntie as ‘Hayley can’t get out of bed’ and told to his grandma, who now thinks I’m a lazy, terrible person 🤣\n",
      "@Microsoft Why do I pay for WORD when it functions so poorly on my @SamsungUS Chromebook? 🙄\n",
      "CSGO matchmaking is so full of closet hacking, it's a truly awful game.\n",
      "Hi @EAHelp I’ve had Madeleine McCann in my cellar for the past 13 years and the little sneaky thing just escaped whilst I was loading up some fifa points, she took my card and I’m having to use my paypal account but it isn’t working, can you help me resolve it please?\n",
      "FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        \"\"\"\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements. It ensures only valid strings are processed.\n",
    "        \"\"\"\n",
    "        if not isinstance(tweet, str):\n",
    "            return \"\"  # Return empty string for non-string values (e.g., NaN, float)\n",
    "        \n",
    "        return ' '.join(re.sub(r\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        \"\"\"\n",
    "        Utility function to classify sentiment of passed tweet using TextBlob's sentiment method.\n",
    "        \"\"\"\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def analyze_sentiment(self, df, tweet_column):\n",
    "        \"\"\"\n",
    "        Function to apply sentiment analysis to a dataset of tweets.\n",
    "        \"\"\"\n",
    "        df['sentiment'] = df[tweet_column].apply(self.get_tweet_sentiment)\n",
    "        return df\n",
    "\n",
    "    def calculate_sentiment_percentage(self, df):\n",
    "        \"\"\"\n",
    "        Function to calculate the percentage of each sentiment category.\n",
    "        \"\"\"\n",
    "        total_tweets = len(df)\n",
    "        positive_tweets = len(df[df['sentiment'] == 'positive'])\n",
    "        negative_tweets = len(df[df['sentiment'] == 'negative'])\n",
    "        neutral_tweets = len(df[df['sentiment'] == 'neutral'])\n",
    "\n",
    "        print(f\"Positive tweets percentage: {100 * positive_tweets / total_tweets:.2f}%\")\n",
    "        print(f\"Negative tweets percentage: {100 * negative_tweets / total_tweets:.2f}%\")\n",
    "        print(f\"Neutral tweets percentage: {100 * neutral_tweets / total_tweets:.2f}%\")\n",
    "\n",
    "    def display_sample_tweets(self, df):\n",
    "        \"\"\"\n",
    "        Function to display sample tweets based on sentiment.\n",
    "        \"\"\"\n",
    "        ptweets = df[df['sentiment'] == 'positive']\n",
    "        ntweets = df[df['sentiment'] == 'negative']\n",
    "\n",
    "        print(\"\\nSample Positive tweets:\")\n",
    "        for tweet in ptweets.head(5)['Text']:\n",
    "            print(tweet)\n",
    "\n",
    "        print(\"\\nSample Negative tweets:\")\n",
    "        for tweet in ntweets.head(5)['Text']:\n",
    "            print(tweet)\n",
    "\n",
    "\n",
    "def load_and_process_data(training_path, validation_path):\n",
    "    \"\"\"\n",
    "    Load datasets, process the tweets, and apply sentiment analysis.\n",
    "    \"\"\"\n",
    "    # Load training and validation datasets\n",
    "    df_train = pd.read_csv(training_path, header=None)\n",
    "    df_valid = pd.read_csv(validation_path, header=None)\n",
    "\n",
    "    # Manually rename columns\n",
    "    df_train.columns = ['ID', 'Source', 'Label', 'Text']\n",
    "    df_valid.columns = ['ID', 'Source', 'Label', 'Text']\n",
    "\n",
    "    # Print columns to confirm renaming\n",
    "    print(f\"Training data columns: {df_train.columns}\")\n",
    "    print(f\"Validation data columns: {df_valid.columns}\")\n",
    "\n",
    "    # Use 'Text' column for sentiment analysis\n",
    "    tweet_column = 'Text'\n",
    "\n",
    "    # Initialize sentiment analyzer\n",
    "    analyzer = SentimentAnalyzer()\n",
    "\n",
    "    # Analyze sentiment for both training and validation datasets\n",
    "    df_train = analyzer.analyze_sentiment(df_train, tweet_column)\n",
    "    df_valid = analyzer.analyze_sentiment(df_valid, tweet_column)\n",
    "\n",
    "    # Calculate sentiment percentage\n",
    "    print(\"Training Data Sentiment Analysis:\")\n",
    "    analyzer.calculate_sentiment_percentage(df_train)\n",
    "\n",
    "    print(\"\\nValidation Data Sentiment Analysis:\")\n",
    "    analyzer.calculate_sentiment_percentage(df_valid)\n",
    "\n",
    "    # Display sample tweets\n",
    "    analyzer.display_sample_tweets(df_train)\n",
    "    analyzer.display_sample_tweets(df_valid)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the correct file paths for your datasets\n",
    "    training_path = 'twitter_training.csv'  # Replace with your training dataset path\n",
    "    validation_path = 'twitter_validation.csv'  # Replace with your validation dataset path\n",
    "\n",
    "    # Load and process data\n",
    "    load_and_process_data(training_path, validation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65b27f-0c73-4105-b929-3863863d545d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
